# SpeechEmotion
Abstract
The goal of speech emotion recognition (SER), a significant research field, is to 
detect a speaker’s emotional state from their speech signal. Deep learning 
methods have significantly increased accuracy when employed for SER in recent 
years, and machine learning techniques have been applied for this purpose. The 
usage of a multi-layer perceptron (MLP) for voice emotion recognition in natural 
language processing is examined in this work (NLP). Mel Frequency Cepstral 
Coefficients (MFCCs) and their derivatives are extracted as features from the 
RAVDESS dataset, which contains speech recordings of 24 actors expressing 
eight different emotions. We use a five-fold cross-validation strategy to assess the 
MLP model’s performance after training it on the retrieved features
Keywords: MLP, Mel Frequency Cepstral Coefficients (MFCC), Speech Signal, 
Support Vector Machines (SVM), Accuracy, Cross-Validation, Speech 
Transcripts.

Introduction
Speech emotion recognition is a rapidly growing field that aims to develop 
systems that can automatically recognize emotions in speech. This technology 
has the potential to improve human-computer interactions in a wide range of 
applications, such as health care, customer service, and entertainment. The ability 
to recognize emotions in speech is a complex task that requires a deep 
understanding of the nuances of human emotion and the ability to extract relevant 
features from speech signals. Current approaches to speech emotion recognition 
rely on a combination of machine learning techniques and hand-crafted features. 
The system will be trained on a dataset of audio recordings labelled with the 
corresponding emotion. In this project we will be exploring more on Natural 
language processing and Machine learning techniques to improve the 
performance of the system by testing and training the models. Speech is a crucial 
component of human communication, and speech is largely influenced by 
emotions. Speech emotion recognition is a crucial problem in a variety of 
applications, including psychotherapy, speech therapy, and human-computer 
interaction. The goal of speech emotion recognition (SER) is to infer the 
School of Computer Science and Engineering, Vellore Institute of Technology, Chennai
speaker’s emotional state from the speech signal. SER is a multi-step procedure 
that includes phases like feature extraction, feature selection, and classification. 
Deep learning-based methods have produced encouraging outcomes in SER in 
recent years. A popular feed forward neural network for classification problems 
is the multi-layer perceptron (MLP).

